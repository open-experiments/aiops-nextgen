# Phase 1 Full Code Tests
# Tests the actual src/shared/ modules against sandbox infrastructure
#
# Tests:
# 1. Pydantic Models (src/shared/models/)
# 2. SQLAlchemy ORM Models (src/shared/database/)
# 3. Redis Client Wrapper (src/shared/redis_client/)
# 4. Config Management (src/shared/config/)
# 5. Structured Logging (src/shared/observability/)

apiVersion: v1
kind: ConfigMap
metadata:
  name: phase1-full-test
  namespace: aiops-nextgen
data:
  run_tests.py: |
    #!/usr/bin/env python3
    """Phase 1 Full Code Tests - Testing actual src/shared/ modules."""

    import asyncio
    import json
    import os
    import sys
    from datetime import datetime, timezone
    from typing import Any
    from uuid import uuid4

    # Results tracking
    results = {"passed": 0, "failed": 0, "tests": []}

    def log_test(name: str, passed: bool, details: str = ""):
        status = "PASS" if passed else "FAIL"
        print(f"[{status}] {name}")
        if details:
            for line in details.split('\n'):
                print(f"       {line}")
        results["tests"].append({"name": name, "passed": passed})
        if passed:
            results["passed"] += 1
        else:
            results["failed"] += 1

    # =========================================================================
    # TEST 1: Pydantic Models (src/shared/models/)
    # =========================================================================

    def test_cluster_models():
        """Test Cluster domain Pydantic models."""
        try:
            from shared.models import (
                Cluster, ClusterCreate, ClusterUpdate, ClusterStatus,
                ClusterType, Platform, Environment, ClusterState,
                ClusterCapabilities, ClusterEndpoints
            )

            # Test ClusterCreate with defaults
            cluster = ClusterCreate(
                name="test-cluster-01",
                api_server_url="https://api.test.example.com:6443"
            )
            assert cluster.cluster_type == ClusterType.SPOKE
            assert cluster.platform == Platform.OPENSHIFT
            assert cluster.environment == Environment.DEVELOPMENT

            # Test full Cluster model
            full_cluster = Cluster(
                id=uuid4(),
                name="prod-cluster",
                api_server_url="https://api.prod.example.com:6443",
                cluster_type=ClusterType.HUB,
                platform=Platform.OPENSHIFT,
                platform_version="4.16.0",
                environment=Environment.PRODUCTION,
                status=ClusterStatus(state=ClusterState.ONLINE),
                endpoints=ClusterEndpoints(
                    prometheus_url="https://prometheus.prod.example.com"
                ),
                capabilities=ClusterCapabilities(has_gpu_nodes=True, gpu_types=["A100"]),
                created_at=datetime.now(timezone.utc),
                updated_at=datetime.now(timezone.utc)
            )

            # Test serialization
            json_data = full_cluster.model_dump_json()
            parsed = json.loads(json_data)
            assert parsed["cluster_type"] == "HUB"
            assert parsed["capabilities"]["has_gpu_nodes"] == True

            log_test("Cluster Domain Models", True,
                     f"ClusterCreate, Cluster, ClusterStatus validated\n"
                     f"Enums: ClusterType, Platform, Environment working")
            return True
        except Exception as e:
            log_test("Cluster Domain Models", False, str(e))
            return False

    def test_observability_models():
        """Test Observability domain Pydantic models."""
        try:
            from shared.models import (
                MetricQuery, MetricResult, MetricSeries,
                MetricResultStatus, MetricResultType,
                Alert, AlertSeverity, AlertState,
                Trace, Span, SpanStatus,
                LogEntry, LogQuery
            )

            # Test MetricQuery
            query = MetricQuery(
                query="container_cpu_usage_seconds_total",
                start=datetime.now(timezone.utc),
                end=datetime.now(timezone.utc),
                step="15s"
            )

            # Test MetricResult
            result = MetricResult(
                cluster_id=uuid4(),
                cluster_name="test-cluster",
                status=MetricResultStatus.SUCCESS,
                result_type=MetricResultType.MATRIX,
                data=[
                    MetricSeries(
                        metric={"__name__": "cpu", "pod": "nginx"},
                        values=[[1703424000, "0.5"], [1703424015, "0.6"]]
                    )
                ]
            )
            assert len(result.data) == 1

            # Test Alert
            alert = Alert(
                id=uuid4(),
                fingerprint="abc123def456",
                cluster_id=uuid4(),
                cluster_name="test-cluster",
                alertname="HighCPU",
                severity=AlertSeverity.CRITICAL,
                state=AlertState.FIRING,
                labels={"pod": "nginx"},
                annotations={"description": "CPU > 90%"},
                starts_at=datetime.now(timezone.utc)
            )

            # Test Trace/Span
            span = Span(
                trace_id="abc123",
                span_id="def456",
                operation_name="HTTP GET /api/clusters",
                service_name="api-gateway",
                duration_ms=45,
                status=SpanStatus.OK,
                start_time=datetime.now(timezone.utc)
            )

            log_test("Observability Domain Models", True,
                     "MetricQuery, MetricResult, Alert, Trace, Span validated")
            return True
        except Exception as e:
            log_test("Observability Domain Models", False, str(e))
            return False

    def test_intelligence_models():
        """Test Intelligence domain Pydantic models."""
        try:
            from shared.models import (
                ChatSession, ChatSessionCreate, ChatMessage, ChatMessageCreate,
                MessageRole, Persona, ToolCall, ToolResult, ToolResultStatus,
                AnomalyDetection, AnomalySeverity, AnomalyType, DetectionType
            )

            # Test Persona
            persona = Persona(
                id="k8s-expert",
                name="Kubernetes Expert",
                description="Expert in K8s troubleshooting",
                system_prompt="You are a Kubernetes expert...",
                capabilities=["get_pods", "get_logs", "query_metrics"]
            )
            assert len(persona.capabilities) == 3

            # Test ChatSession
            session = ChatSession(
                id=uuid4(),
                user_id="user@example.com",
                persona_id="k8s-expert",
                cluster_context=[uuid4()],
                message_count=0,
                created_at=datetime.now(timezone.utc),
                updated_at=datetime.now(timezone.utc)
            )

            # Test ChatMessage with tool calls
            message = ChatMessage(
                id=uuid4(),
                session_id=session.id,
                role=MessageRole.ASSISTANT,
                content="Let me check the pods...",
                tool_calls=[
                    ToolCall(id="call_1", name="get_pods", arguments={"namespace": "default"})
                ],
                created_at=datetime.now(timezone.utc)
            )

            # Test AnomalyDetection
            anomaly = AnomalyDetection(
                id=uuid4(),
                cluster_id=uuid4(),
                metric_name="container_memory_usage_bytes",
                detection_type=DetectionType.STATISTICAL,
                severity=AnomalySeverity.HIGH,
                confidence_score=0.92,
                anomaly_type=AnomalyType.SPIKE,
                expected_value=1073741824,
                actual_value=3221225472,
                deviation_percent=200.0,
                explanation="Memory usage 3x higher than baseline",
                detected_at=datetime.now(timezone.utc)
            )

            log_test("Intelligence Domain Models", True,
                     "Persona, ChatSession, ChatMessage, ToolCall, AnomalyDetection validated")
            return True
        except Exception as e:
            log_test("Intelligence Domain Models", False, str(e))
            return False

    def test_event_and_report_models():
        """Test Event and Report domain models."""
        try:
            from shared.models import (
                Event, EventType, Subscription, SubscriptionRequest,
                Report, ReportRequest, ReportType, ReportFormat
            )

            # Test Event
            event = Event(
                event_id=uuid4(),
                event_type=EventType.CLUSTER_REGISTERED,
                source="cluster-registry",
                cluster_id=uuid4(),
                timestamp=datetime.now(timezone.utc),
                payload={"name": "new-cluster", "type": "SPOKE"}
            )
            json_event = event.model_dump_json()
            assert "CLUSTER_REGISTERED" in json_event

            # Test Subscription
            subscription = Subscription(
                id=uuid4(),
                client_id="frontend-123",
                event_types=[EventType.ALERT_FIRED, EventType.GPU_UPDATE],
                created_at=datetime.now(timezone.utc)
            )

            # Test Report
            report = Report(
                id=uuid4(),
                title="Weekly Cluster Health Report",
                report_type=ReportType.EXECUTIVE_SUMMARY,
                format=ReportFormat.PDF,
                cluster_scope=[uuid4(), uuid4()],
                generated_by="system",
                storage_path="/reports/weekly-2024-12-24.pdf",
                size_bytes=2048000,
                created_at=datetime.now(timezone.utc)
            )

            log_test("Event & Report Models", True,
                     "Event, EventType (all types), Subscription, Report validated")
            return True
        except Exception as e:
            log_test("Event & Report Models", False, str(e))
            return False

    # =========================================================================
    # TEST 2: SQLAlchemy ORM Models (src/shared/database/)
    # =========================================================================

    async def test_sqlalchemy_models():
        """Test SQLAlchemy ORM models with actual database."""
        try:
            from sqlalchemy import text
            from shared.database import (
                Base, create_engine, create_session_factory,
                ClusterModel, ClusterHealthHistoryModel,
                ChatSessionModel, ChatMessageModel,
                AnomalyDetectionModel, ReportModel
            )

            # Build connection URL
            db_url = (
                f"postgresql+asyncpg://"
                f"{os.environ['POSTGRES_USER']}:{os.environ['POSTGRES_PASSWORD']}"
                f"@{os.environ['POSTGRES_HOST']}:{os.environ['POSTGRES_PORT']}"
                f"/{os.environ['POSTGRES_DB']}"
            )

            engine = create_engine(db_url)
            SessionFactory = create_session_factory(engine)

            async with engine.begin() as conn:
                # Create tables
                await conn.run_sync(Base.metadata.create_all)

            # Test ClusterModel CRUD
            async with SessionFactory() as session:
                cluster = ClusterModel(
                    name="sqlalchemy-test-cluster",
                    api_server_url="https://api.test.example.com:6443",
                    cluster_type="SPOKE",
                    platform="OPENSHIFT",
                    environment="DEVELOPMENT",
                    status={"state": "ONLINE"}
                )
                session.add(cluster)
                await session.commit()

                # Query back
                result = await session.execute(
                    text("SELECT name, cluster_type FROM clusters.clusters WHERE name = :name"),
                    {"name": "sqlalchemy-test-cluster"}
                )
                row = result.fetchone()
                assert row[0] == "sqlalchemy-test-cluster"
                assert row[1] == "SPOKE"

                # Test ChatSessionModel
                chat_session = ChatSessionModel(
                    user_id="test@example.com",
                    persona_id="k8s-expert",
                    title="Test Session"
                )
                session.add(chat_session)
                await session.commit()

                # Clean up
                await session.execute(
                    text("DELETE FROM clusters.clusters WHERE name = :name"),
                    {"name": "sqlalchemy-test-cluster"}
                )
                await session.execute(
                    text("DELETE FROM intelligence.chat_sessions WHERE user_id = :user"),
                    {"user": "test@example.com"}
                )
                await session.commit()

            await engine.dispose()

            log_test("SQLAlchemy ORM Models", True,
                     "ClusterModel CRUD, ChatSessionModel CRUD\n"
                     "Tables created in clusters/intelligence schemas")
            return True
        except Exception as e:
            log_test("SQLAlchemy ORM Models", False, str(e))
            return False

    # =========================================================================
    # TEST 3: Redis Client Wrapper (src/shared/redis_client/)
    # =========================================================================

    async def test_redis_client_wrapper():
        """Test the actual Redis client wrapper module."""
        try:
            from shared.redis_client import RedisClient, RedisDB
            from shared.models import Event, EventType

            redis_url = f"redis://{os.environ['REDIS_HOST']}:{os.environ['REDIS_PORT']}"
            client = RedisClient(redis_url)
            await client.connect()

            # Test health check
            health = await client.health_check()
            assert health["status"] == "healthy"

            # Test cache operations (DB 2)
            await client.cache_set("clusters", "test-key", {"name": "test", "status": "online"}, ttl_seconds=60)
            cached = await client.cache_get_json("clusters", "test-key")
            assert cached["name"] == "test"

            deleted = await client.cache_delete("clusters", "test-key")
            assert deleted == True

            # Test rate limiting (DB 1)
            allowed, remaining = await client.check_rate_limit("test-user", "/api/clusters", limit=10, window_seconds=60)
            assert allowed == True
            assert remaining == 9

            # Test session operations (DB 3)
            session_id = str(uuid4())
            await client.session_set(session_id, {"user": "test@example.com", "role": "admin"}, ttl_seconds=60)
            session_data = await client.session_get(session_id)
            assert session_data["user"] == "test@example.com"
            await client.session_delete(session_id)

            # Test pub/sub (DB 0)
            event = Event(
                event_id=uuid4(),
                event_type=EventType.CLUSTER_REGISTERED,
                source="test",
                timestamp=datetime.now(timezone.utc),
                payload={"test": True}
            )
            subscribers = await client.publish_event(event)

            await client.close()

            log_test("Redis Client Wrapper", True,
                     f"Health check: all 4 DBs healthy\n"
                     f"Cache ops (DB 2): SET/GET/DELETE\n"
                     f"Rate limit (DB 1): check_rate_limit\n"
                     f"Sessions (DB 3): SET/GET/DELETE\n"
                     f"PubSub (DB 0): publish_event")
            return True
        except Exception as e:
            log_test("Redis Client Wrapper", False, str(e))
            return False

    # =========================================================================
    # TEST 4: Config Management (src/shared/config/)
    # =========================================================================

    def test_config_management():
        """Test configuration management module."""
        try:
            from shared.config import (
                Settings, get_settings,
                DatabaseSettings, RedisSettings, LLMSettings,
                Environment, LogLevel, LogFormat, LLMProvider
            )

            # Test Settings loads from environment
            settings = get_settings()
            assert settings.app_name == "aiops-nextgen"

            # Test DatabaseSettings
            db_settings = DatabaseSettings()
            assert db_settings.port == 5432
            assert "postgresql" in db_settings.url
            assert "asyncpg" in db_settings.async_url

            # Test RedisSettings
            redis_settings = RedisSettings()
            assert redis_settings.port == 6379
            assert "redis://" in redis_settings.url

            # Test LLMSettings defaults (local vLLM preferred)
            llm_settings = LLMSettings()
            assert llm_settings.provider == LLMProvider.LOCAL
            assert "v1" in llm_settings.local_url

            # Test enums
            assert Environment.PRODUCTION.value == "production"
            assert LogLevel.DEBUG.value == "DEBUG"
            assert LogFormat.JSON.value == "json"

            # Test nested settings access
            assert settings.database.port == 5432
            assert settings.llm.provider == LLMProvider.LOCAL

            log_test("Config Management", True,
                     "Settings, DatabaseSettings, RedisSettings, LLMSettings\n"
                     "Environment variables loading, nested access working")
            return True
        except Exception as e:
            log_test("Config Management", False, str(e))
            return False

    # =========================================================================
    # TEST 5: Structured Logging (src/shared/observability/)
    # =========================================================================

    def test_structured_logging():
        """Test structured logging module."""
        try:
            from shared.observability import (
                setup_logging, get_logger,
                RequestContextManager,
                log_request_start, log_request_end,
                request_id_var, user_id_var
            )
            from shared.config import LogFormat, LogLevel

            # Setup logging
            setup_logging(log_level=LogLevel.DEBUG, log_format=LogFormat.TEXT)

            # Get logger
            logger = get_logger("test")
            assert logger is not None

            # Test context manager
            with RequestContextManager(request_id="req-123", user_id="test@example.com"):
                assert request_id_var.get() == "req-123"
                assert user_id_var.get() == "test@example.com"
                logger.info("Test log message", extra_field="value")

            # Test log helpers
            log_request_start(logger, "GET", "/api/clusters")
            log_request_end(logger, "GET", "/api/clusters", 200, 45.5)

            log_test("Structured Logging", True,
                     "setup_logging, get_logger working\n"
                     "RequestContextManager with context vars\n"
                     "log_request_start/end helpers")
            return True
        except Exception as e:
            log_test("Structured Logging", False, str(e))
            return False

    # =========================================================================
    # MAIN
    # =========================================================================

    async def main():
        print("=" * 70)
        print("AIOps NextGen - Phase 1 FULL CODE TESTS")
        print("Testing actual src/shared/ modules")
        print("=" * 70)
        print()

        # Test 1: Pydantic Models
        print("--- TEST 1: Pydantic Models (src/shared/models/) ---")
        test_cluster_models()
        test_observability_models()
        test_intelligence_models()
        test_event_and_report_models()
        print()

        # Test 2: SQLAlchemy ORM
        print("--- TEST 2: SQLAlchemy ORM (src/shared/database/) ---")
        await test_sqlalchemy_models()
        print()

        # Test 3: Redis Client
        print("--- TEST 3: Redis Client (src/shared/redis_client/) ---")
        await test_redis_client_wrapper()
        print()

        # Test 4: Config Management
        print("--- TEST 4: Config Management (src/shared/config/) ---")
        test_config_management()
        print()

        # Test 5: Structured Logging
        print("--- TEST 5: Structured Logging (src/shared/observability/) ---")
        test_structured_logging()
        print()

        # Summary
        print("=" * 70)
        total = results["passed"] + results["failed"]
        print(f"PHASE 1 CODE TESTS: {results['passed']}/{total} passed, {results['failed']} failed")
        print("=" * 70)

        sys.exit(0 if results["failed"] == 0 else 1)

    if __name__ == "__main__":
        asyncio.run(main())

---
apiVersion: batch/v1
kind: Job
metadata:
  name: phase1-code-tests
  namespace: aiops-nextgen
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: test-runner
          image: python:3.11-slim
          command:
            - /bin/bash
            - -c
            - |
              set -e
              export HOME=/tmp/home
              mkdir -p $HOME

              echo "Installing dependencies..."
              pip install --quiet --cache-dir=/tmp/pip-cache \
                pydantic pydantic-settings \
                sqlalchemy[asyncio] asyncpg \
                redis structlog

              echo "Verifying shared package structure..."
              ls -la /app/src/shared/
              ls -la /app/src/shared/models/

              export PYTHONPATH=/app/src

              echo "Running Phase 1 code tests..."
              python /tests/run_tests.py
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            capabilities:
              drop:
                - ALL
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: POSTGRES_HOST
              value: "postgresql"
            - name: POSTGRES_PORT
              value: "5432"
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgresql-credentials
                  key: POSTGRES_USER
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgresql-credentials
                  key: POSTGRES_PASSWORD
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: postgresql-credentials
                  key: POSTGRES_DB
            - name: REDIS_HOST
              value: "redis"
            - name: REDIS_PORT
              value: "6379"
            - name: ENV
              value: "development"
            - name: LOG_LEVEL
              value: "DEBUG"
            - name: LOG_FORMAT
              value: "text"
          volumeMounts:
            - name: test-script
              mountPath: /tests
            - name: shared-root
              mountPath: /app/src/shared
            - name: shared-models
              mountPath: /app/src/shared/models
            - name: shared-database
              mountPath: /app/src/shared/database
            - name: shared-redis-client
              mountPath: /app/src/shared/redis_client
            - name: shared-config
              mountPath: /app/src/shared/config
            - name: shared-observability
              mountPath: /app/src/shared/observability
            - name: tmp-home
              mountPath: /tmp/home
            - name: pip-cache
              mountPath: /tmp/pip-cache
      volumes:
        - name: test-script
          configMap:
            name: phase1-full-test
        - name: shared-root
          configMap:
            name: shared-root
        - name: shared-models
          configMap:
            name: shared-models
        - name: shared-database
          configMap:
            name: shared-database
        - name: shared-redis-client
          configMap:
            name: shared-redis-client
        - name: shared-config
          configMap:
            name: shared-config
        - name: shared-observability
          configMap:
            name: shared-observability
        - name: tmp-home
          emptyDir: {}
        - name: pip-cache
          emptyDir: {}
